# Intelligence Explosion

The intelligence explosion refers to the rapid transition from human-level AGI to vastly superhuman superintelligence, potentially occurring in less than one year through automated AI research.

## Core Mechanism

Once AGI can automate AI research itself, we enter a feedback loop:
1. AGI automates the work of AI researchers/engineers
2. Millions of automated researchers work 24/7 at increasing speeds
3. Algorithmic breakthroughs compress decades of progress into months
4. Each new model generation becomes dramatically more capable
5. Process accelerates until reaching vastly superhuman systems

## Scale of Automated Research

By 2027, inference fleets should support:
- **100 million human-researcher-equivalents** running simultaneously
- Each thinking at **100 tokens/minute** (human internal monologue speed)
- Soon accelerating to **10x-100x human speed** via algorithmic speedups
- Equivalent to generating entire internet's worth of tokens daily

This represents >100,000x increase in research effort compared to a few hundred researchers at leading labs today.

## Expected Acceleration

Conservative estimate: **10x acceleration** of algorithmic progress
- Historical trend: ~0.5 OOMs/year (with human researchers)
- Intelligence explosion: **5+ OOMs in <1 year** (with automated researchers)
- Comparable to another GPT-2-to-GPT-4 jump on top of AGI

The vast advantages of automated researchers:
- Read entire ML literature and every experiment ever run
- Write millions of lines of perfect code
- Coordinate perfectly across millions of copies
- Never need training or onboarding (just replicate)
- Accumulate millennia of equivalent experience in weeks

## Bottlenecks

**Compute for experiments**: Most significant constraint
- Million times more researchers won't mean million times faster progress
- Limited by available compute to test ideas empirically
- Mitigations: smaller-scale experiments, better intuitions, efficiency gains
- Even with bottleneck, 10x acceleration seems plausible

**Complementarities**: Last 10% of capabilities may be hardest
- May need 1-2 years for full automation rather than immediate
- Proto-automated researchers (2026/27) â†’ full automation (2028/29)

**Diminishing returns**: Ideas get harder to find
- But million-fold increase in research effort far exceeds what's needed to sustain 0.5 OOMs/year
- "Level effect" from one-time boost likely overcomes diminishing returns

## Power of Superintelligence

By end of intelligence explosion:
- **Quantitatively superhuman**: Billions of agents, 100x+ human speed
- **Qualitatively superhuman**: Novel behaviors beyond human understanding (like AlphaGo's move 37)
- Systems as smart as PhDs will seem like elementary schoolers compared to final superintelligence

## Broader Impacts

Explosive progress expands beyond AI research to:
- Solving robotics within years
- Dramatic scientific/technological breakthroughs across all fields
- Economic growth rates of 30%+/year (vs. historical 2%)
- [[decisive-military-advantage]] for whoever achieves it first

## See Also
- [[automated-ai-research]]
- [[superintelligence]]
- [[agi-timeline]]
- [[superalignment-problem]]
