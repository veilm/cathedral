# Algorithmic Secrets

The algorithmic breakthroughs being developed right now (2024-2025) are perhaps the most valuable and vulnerable national security assets—worth 10x-100x larger clusters to adversaries, yet protected worse than "random startup security."

## Why They Matter More Than You Think

**Comparable to compute scaling**:
- [[algorithmic-efficiency]] has contributed roughly half of AI progress historically
- ~0.5 OOMs/year trend means multiple OOMs-worth between now and AGI
- American labs likely years ahead; defending secrets could mean 10x-100x compute advantage

**More valuable than chip export controls**:
- Export controls perhaps give China 3x higher compute costs
- "Yet we're leaking 3x algorithmic secrets all over the place!"
- Far more cost-effective way to maintain advantage

**The 'EUV of algorithms'**: [[data-wall]] Solutions

Current paradigm (naive LLM pretraining) hitting wall soon. Labs furiously working on next paradigm:
- Reinforcement learning approaches
- Synthetic data generation
- Self-play mechanisms
- Sample efficiency breakthroughs
- "AlphaGo self-play equivalent for general intelligence"

These will be "as key as the invention of the LLM paradigm originally was" and "the key to building systems that go far beyond human-level."

**Critical window**: "In the next 12-24 months, we will leak key AGI breakthroughs to the CCP" if security not improved.

## The Divergence

Up until ~2 years ago, everything was published:
- Basic idea public: scale up Transformers on internet text
- Many details public: Chinchilla scaling laws, MoE, etc.
- Open source models pretty good as result
- Many companies competitive based on funding/cluster size

**Now changing dramatically**:
- Basically all frontier progress happens at labs (academia surprisingly irrelevant)
- Leading labs stopped publishing advances
- Should expect far more divergence ahead
- Between labs, between countries, between proprietary frontier and open source
- "A few American labs will be way ahead—a moat worth 10x, 100x, or more"

## Current State of 'Security'

**Catastrophically bad**:
- Thousands of people with access to most important secrets
- "Basically no background-checking, silo'ing, controls, basic infosec"
- Stored on easily hackable SaaS services
- "People gabber at parties in SF"
- Can "just look through office windows"
- Anyone could be offered $100M and recruited to Chinese lab
- ByteDance reportedly emailed basically every person on Google Gemini paper offering very senior positions

**Public leaks**: "Many articles, and rumors flying around SF, purporting to have extensive details of various lab algorithmic advances"

**Comparison**: "AI lab security isn't much better than 'random startup security.' Directly selling the AGI secrets to the CCP would at least be more honest."

**Marc Andreessen assessment**: "Chinese penetration of these labs would be trivially easy using any number of industrial espionage methods, such as simply bribing the cleaning crew to stick USB dongles into laptops. My own assumption is that all such American AI labs are fully penetrated and that China is getting nightly downloads of all American AI research and code RIGHT NOW…"

## What Protection Requires

**Defensibility**: Only dozens of people truly "need to know" key implementation details for given breakthrough
- Can vet, silo, intensively monitor these people
- Radically upgraded infosec
- Much tighter than base model development (thousands involved)

**Low-hanging fruit**: Merely adopting best practices from secretive hedge funds or Google-customer-data-level security would drastically improve situation
- Quantitative trading firms (Jane Street, etc.) manage similar challenge
- Hour-long conversation could relay enough to make firm's alpha go to zero
- Yet they successfully preserve secrets and retain edge

**Government help eventually required**: For state-actor-proof security against full MSS effort
- Private companies regularly hacked (Microsoft executives' emails recently stolen by Russians)
- High-level security expert estimate: even with private crash course, China would likely exfiltrate if their #1 priority
- Only government has infrastructure, know-how, authority for single-digit-percent security

## Why Labs Resist

**Tragedy of commons**:
- Individual lab taking 10% slowdown for security = competitive disadvantage
- But national interest: all labs at 90% speed with secrets protected >> 100% speed with everything instantly stolen

**Commercial incentives prevail**: "Whenever it comes time to make hard choices to prioritize security, startup attitudes and commercial interests prevail over the national interest"

**The dissonance**: Labs full-throatedly claim to be building AGI this decade, acknowledge national security importance, reportedly plan $7T chip buildouts that only make sense if AGI-pilled, and "acknowledge 'of course, we'll all be in a bunker' and smirk."

Yet reality: "The national security advisor would have a mental breakdown if he understood the level of security at the nation's leading AI labs."

## Probable Path to China

Author's assessment: "Failing to protect algorithmic secrets is probably the most likely way in which China is able to stay competitive in the AGI race."

Even if China can't outbuild on compute, and even if chips remain constrained, stolen algorithms would:
- Overcome any US algorithmic advantage (worth more than compute advantages)
- Enable training competitive models on inferior hardware
- Provide solutions to [[data-wall]] that keep them stuck otherwise

**Tacit knowledge objection**: Some argue stolen secrets won't help without tacit knowledge of large-scale training
- Author disagrees: Chinese AI efforts shown capable of large-scale training
- Two layers: bottom (engineering prowess) vs. top (algorithmic recipe)
- Bottom layer: China already has indigenously
- Top layer: "Could be conveyed in a one-hour call"
- Discrete algorithmic changes transfer across underlying tacit knowledge

## Timeline Urgency

"There are secrets being developed right now, that can be used for every training run in the future and will be the key unlocks to AGI, that are protected by the security of a startup and will be worth hundreds of billions of dollars to the CCP."

**Irreversible damage window**: 12-24 months from June 2024
- Developing key algorithmic breakthroughs for AGI right now
- Once leaked, can't be unleaked
- Will determine whether US retains algorithmic advantage through 2027+
- "Our failure today will be irreversible soon"

## See Also
- [[ai-lab-security]]
- [[data-wall]]
- [[algorithmic-efficiency]]
- [[china-competition]]
- [[the-project]]
