# Counting the OOMs Framework
The series centers on a forecasting heuristic: track orders of magnitude (OOMs, 10x steps) in effective compute and infer capability jumps from historical scaling behavior.

## Core Claim
The framework says frontier capability growth is mostly explained by three multiplicative drivers:
- Physical training compute scaleup.
- Algorithmic efficiency gains (compute multipliers).
- “Unhobbling” gains that unlock latent capability into practical performance.

From GPT-2 (2019) to GPT-4 (2023), the claimed base-model effective-compute increase is roughly 4.5–6 OOMs, plus major unhobbling from raw model to useful chatbot. The forward-looking claim is another 3–6 OOMs by end-2027 (best guess ~5), plus another unhobbling wave from chatbot to agent-like coworker behavior.

## Why This Is Treated as Predictive
The essay argues that deep-learning scaling trends have been unusually stable over many OOMs and many years, while expert skepticism repeatedly underestimated short-horizon progress (for example, benchmark jumps on MATH and broad test performance growth between GPT-3.5 and GPT-4). The policy implication is not certainty, but that “AGI this decade” becomes a mainstream forecast under simple extrapolation rather than sci-fi assumptions.

## Forecast Output
On this framing, end-2027 systems plausibly automate most remote cognitive work, including substantial fractions of AI research labor itself. That is the hinge for [[intelligence-explosion-mechanism]], because automating AI R&D feeds back into faster algorithmic progress.

The framework also embeds a timing asymmetry: the 2020s are viewed as a one-time high-OOM buildout era (capital, chips, power, talent concentration), while post-early-2030s progress could slow if easy scaleup is exhausted. This is the “this decade or bust” argument.

## Error Bars and Failure Modes
The author emphasizes uncertainty around:
- Data constraints and whether post-LLM training paradigms break through ([[data-wall-and-post-llm-paradigms]]).
- Whether unhobbling reaches robust long-horizon agency ([[unhobbling-and-agent-coworkers]]).
- Whether geopolitical/security shocks disrupt the baseline scaling path ([[ai-lab-security-and-agi-secrets]]).

Still, the thesis is that ignoring these trendlines is less rational than taking transformative timelines seriously and preparing accordingly.

## See also
- [[compute-and-algorithmic-scaling]]
- [[agi-by-2027-scenario]]
