# Trillion-Dollar Cluster Buildout
The series argues the AGI race is an industrial mobilization problem as much as an ML problem: chips, datacenters, and especially power become strategic bottlenecks.

## Training Cluster Escalation
Using ~0.5 OOM/year training-compute trend, the essay sketches a path from GPT-4-era clusters to:
- 2028-class clusters in the $100B range with ~10 GW power.
- 2030-class clusters in the $1T+ range with ~100 GW power.

Power analogies are explicit: a 100 GW continuous load is over 20% of current US electricity generation.

## Total Ecosystem Spend
Beyond largest training runs, total annual AI capex is modeled as much larger because of inference fleets and multiple competitors. A stylized trajectory grows from roughly $100B–$200B in 2024 toward much higher annual spend by late decade, with massive demand for advanced packaging, HBM, networking, and logic capacity.

## Constraint Hierarchy
The essay’s hierarchy is:
1. Power siting/permitting and grid buildout.
2. Datacenter construction speed.
3. Packaging/memory bottlenecks.
4. Logic wafer capacity (important but less immediately binding).

The US is portrayed as capable but institutionally slow; deregulation/permitting reform and gas-backed rapid buildout are presented as emergency options.

## Geostrategic Siting
Compute geography is treated as national-security critical. The essays warn against locating frontier clusters in non-allied autocracies because of seizure/coercion/exfiltration risk, and tie cluster siting directly to [[ai-lab-security-and-agi-secrets]].

## Role in the Broader Thesis
Without this physical buildout, [[agi-by-2027-scenario]] weakens. With it, both capability acceleration and geopolitical stakes intensify, feeding into [[us-china-agi-race-and-free-world-strategy]] and [[the-project-government-led-agi-endgame]].

## See also
- [[compute-and-algorithmic-scaling]]
- [[superintelligence-power-and-economic-regime-shift]]
