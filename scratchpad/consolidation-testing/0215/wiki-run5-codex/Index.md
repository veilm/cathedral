# Situational Awareness Wiki
This wiki consolidates Leopold Aschenbrenner’s June 2024 *Situational Awareness: The Decade Ahead* into a concept graph. It captures the series’ core forecasts, quantitative assumptions, and policy arguments about AGI timelines, intelligence explosion dynamics, industrial constraints, security, alignment, and geopolitics. The organizing principle is cross-cutting concepts rather than chapter summaries.

## Forecast Mechanics
- [[counting-the-ooms-framework]]: The central forecasting heuristic (compute + algorithms + unhobbling) and why it implies short transformative timelines.
- [[compute-and-algorithmic-scaling]]: How physical compute growth and algorithmic efficiency are treated as joint drivers of capability.
- [[data-wall-and-post-llm-paradigms]]: The key uncertainty around running out of high-quality data and potential post-LLM breakthroughs.
- [[unhobbling-and-agent-coworkers]]: Why posttraining/agent loops may shift systems from chatbot tools to drop-in remote workers.
- [[agi-by-2027-scenario]]: Functional AGI-by-2027 case, assumptions, and failure modes.

## Takeoff Dynamics
- [[intelligence-explosion-mechanism]]: Recursive acceleration via automated AI research and expected bottlenecks.
- [[superintelligence-power-and-economic-regime-shift]]: Claimed effects on science, industry, growth regimes, and military power.

## Infrastructure and Security
- [[trillion-dollar-cluster-buildout]]: Datacenter/chip/power mobilization path to $100B and $1T-class clusters.
- [[ai-lab-security-and-agi-secrets]]: Weight and algorithm security, espionage threat models, and required hardening levels.
- [[superalignment-and-superdefense]]: Why RLHF-style supervision breaks at superhuman levels and the layered defense approach.

## Geopolitics and Governance
- [[us-china-agi-race-and-free-world-strategy]]: Argument that superintelligence lead is decisive and that lead-length affects safety.
- [[the-project-government-led-agi-endgame]]: Forecast that AGI development transitions to a government-led national-security project.
- [[agi-realism-and-parting-thesis]]: Closing doctrine (“AGI realism”) and the series-wide synthesis.

## Key Timeline (Series Scenario)
- 2019–2023: GPT-2 to GPT-4 as one major qualitative jump explained by OOM scaling and unhobbling.
- 2024–2027: Another large effective-compute jump, with agentization and possible AGI-level automation of remote cognitive work.
- ~2027–2028: Rising probability of government-led AGI coordination (“The Project”).
- Late 2020s onward: Potential intelligence explosion, then broader economic/military transformation and high-stakes stabilization phase.
