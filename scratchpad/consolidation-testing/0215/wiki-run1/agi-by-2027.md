# AGI by 2027

AGI (Artificial General Intelligence) by 2027 is "strikingly plausible" based on straightforward trend extrapolation of deep learning progress.

## The Central Argument

From GPT-2 (2019) to GPT-4 (2023), AI capabilities progressed from ~preschooler-level to ~smart high-schooler level in 4 years. If similar progress continues through 2027, we should expect another qualitative jump of similar magnitude—potentially reaching systems capable of automating cognitive work including AI research itself.

This isn't based on "sci-fi" speculation but on [[counting-the-ooms|counting the OOMs]] (orders of magnitude) across three key dimensions:
- ~2-3 OOMs from [[compute-scaling|compute scaling]]
- ~2 OOMs from [[algorithmic-efficiency|algorithmic efficiencies]]
- Major gains from [[unhobbling|unhobbling]]

## Progression of Capabilities

**GPT-2 (2019)**: Could occasionally string together coherent sentences. Struggled to count to 5. Performance comparable to a preschooler impressing adults with vocabulary.

**GPT-3 (2020)**: Could generate simple copy for marketing, demonstrate few-shot learning. Elementary school level.

**GPT-4 (2023)**: Writes sophisticated code, reasons through difficult high-school competition math, scores in top percentiles on AP exams and SAT. Smart high-schooler level.

**2027 systems (projected)**: Should outperform PhDs and expert researchers. Capable of autonomous work on complex projects over extended time horizons—functioning as "drop-in remote workers."

## What AGI Means Here

Not just "a better chatbot" but systems that can:
- Fully automate cognitive jobs that can be done remotely
- Work autonomously on complex, multi-week projects
- Perform at or above expert human level across domains
- Most critically: **Automate AI research itself**

The last point is decisive—once AI systems can automate AI research, they enable the [[intelligence-explosion|intelligence explosion]].

## Why This Decade

We're "racing through the OOMs" faster than historical norms:
- Moore's Law was ~1-1.5 OOMs per decade
- Current AI progress: ~1 OOM per year in effective compute
- This rate won't continue indefinitely—it's driven by one-time scaling factors (spending scaleup, hardware specialization for AI, low-hanging algorithmic fruit)
- After this decade, progress will slow to more glacial rates

If the current scaleup doesn't achieve AGI in 5-10 years, AGI might be "a long way out."

## Uncertainty & Variance

Major sources of uncertainty:
- The [[data-wall|data wall]] could stall progress if solutions aren't found
- [[unhobbling|Unhobbling]] might not progress as far as hoped
- Decade-long trendlines could break

But the opposite is also possible—algorithmic breakthroughs could accelerate timelines.

## See Also

- [[counting-the-ooms|Counting the OOMs]]
- [[intelligence-explosion|Intelligence Explosion]]
- [[automated-ai-research|Automated AI Research]]
- [[data-wall|The Data Wall]]
