# The Project

The Project refers to the inevitable US government-led effort to develop AGI and superintelligence, expected to begin around 2026-2028 as the national security state realizes the stakes involved.

## Core Thesis

**Descriptive claim**: Whether we like it or not, superintelligence development will become primarily a government/national security project, not remain a private startup endeavor.

**Timing**: By late 2026/27/28, some form of government AGI project will be underway, analogous to the Manhattan Project.

## Path to The Project

### The Awakening (2025-2027)

Similar to COVID response trajectory—government seems asleep, then extraordinary mobilization:

**2023**: Already significant shift
- AGI went from fringe topic to Senate hearings and world leader summits
- USG engagement impressive given how early in timeline
- But still "a couple more 2023s" needed to fully open Overton window

**2025-2026**: Truly shocking leaps expected
- AI driving $100B+ annual revenues for big tech
- Models outcompeting PhDs in raw problem-solving
- $10T company valuations, AI mania everywhere
- $100B+ clusters being built

**2026-2027**: Consensus forms
- $100B clusters training models
- AI agents/drop-in remote workers automating software engineering
- Broad consensus among leading scientists/executives/officials: we are on cusp of AGI
- Terrifying demonstrations (bioweapon assistance, autonomous hacking, etc.)
- CCP launches formidable AGI effort becomes evident
- Discovery of CCP infiltration of US labs causes stir

**2027-2028**: Decision point
- Mood in Washington becomes "somber"
- People viscerally feel what's happening, become scared
- Obvious question echoes through Pentagon and Congress: **"Do we need an AGI Manhattan Project?"**
- Becomes clear: this is most important national security challenge since atomic bomb
- National security state gets heavily involved

### Implementation

Not literal nationalization (AI lab researchers becoming military employees), but "suave orchestration":

**Possible structures**:
- Defense contracting relationship (like Boeing/Lockheed Martin)
- Joint venture between cloud providers, AI labs, and government
- "Voluntary" agreements to merge in national effort (like 2023 White House AI commitments)
- Congressional involvement given trillions in investment
- Secure facility for core AGI research team (few hundred researchers)
- Trillion-dollar cluster built in record time

**Timeline**: Underway by late 26/27/28, core team moved to secure location

## Why The Project Is Necessary

### 1. Superintelligence as National Defense Project

By early 2030s:
- Entire US arsenal will be obsolete
- Need wholesale replacement, not just modernization
- Deployment of superintelligence for defensive applications becomes priority (counter superhuman hacking, drone swarms, synthetic biology threats, etc.)
- Requires extremely close cooperation with national security state

"Whether nominally private or not, the AGI project will need to be, will be, integrally a defense project."

### 2. Sane Chain of Command

**The power problem**:
- Individual CEO would have power to coup US government with superintelligence
- Comparable to nuclear weapons command and control
- Random nonprofit board could "decide to seize control of nuclear arsenal"

**Historical precedent**:
- Society decided democratic governments should control military
- Superintelligence will be most powerful military weapon (at first)
- Institutions/constitutions/checks-and-balances have "withstood test of hundreds of years"
- Special AI lab governance "collapsed the first time tested"

**Current situation**:
- US military could already kill every civilian if it wanted
- We don't keep power in check through private companies with own arsenals
- Only one proven chain of command and set of institutions for this task

**Normative disagreement possible** (libertarians: "let Elon and Sam command own nuclear arsenals!") but once superintelligence as national security matter becomes clear, DC will act.

### 3. Security Requirements

See [[ai-security]] for details.

Private companies cannot achieve state-actor-proof security:
- Microsoft regularly hacked by state actors (2024: Russians stole exec emails, government emails)
- Even complete private crash course likely insufficient vs. China's #1 priority
- Only single-digit % exfiltration probability requires government project

**What only USG can provide**:
- Authority for intense employee vetting
- Imprisonment threat for leaking (vs. civil lawsuits)
- Physical security for datacenters
- NSA/intelligence community expertise
- SCIF facilities and security clearance systems
- Counterintelligence capabilities

**Severity**: "Security alone is sufficient to necessitate the government project—both the free world's preeminence and AI safety are doomed if we can't lock this stuff down."

### 4. Safety Management

[[Superalignment]] challenges require more than startup capabilities:

**Problem with private labs**:
- Startup commercial incentives
- Competition pushes racing through intelligence explosion
- Some actors willing to throw safety aside
- Without coordination, no one can "spend lead" for safety time

**Regulation insufficient**:
- Too slow/bureaucratic for intelligence explosion challenges
- Not like "careful evaluations and safety standards"
- More like "fighting a war"

**What's required**:
- Hard calls based on ambiguous data, life-or-death stakes
- "Fog of war" competence
- Insane tradeoffs (e.g., "alignment metrics ambiguous, warning signs for next gen superintelligence, should we delay 3 months? But China stole weights and is racing ahead...")
- Chain of command that can bring necessary seriousness

Not confident government project would be competent, but "superintelligence developed by startups alternative seems much closer to 'praying for the best.'"

### 5. Stabilizing International Situation

Intelligence explosion aftermath will be "one of most volatile and tense situations mankind has ever faced."

**Required capabilities**:
- Win race against authoritarian powers
- Prevent instant theft of superintelligence weights
- Bundle Western efforts (scientists, GPUs, trillions in clusters)
- Protect datacenters against sabotage/attack
- Develop and enforce nonproliferation regime
- Subvert rogue states (Russia, North Korea, Iran, terrorists) from building own superintelligence
- Use superintelligence to harden security of critical infrastructure
- Stabilize offense/defense balance (biology, etc.)
- Tools to control superintelligence and shut down rogue projects
- Handle six-sigma upheavals from compressing century of progress into years

"The task at hand will not be to build cool products. It will be to somehow, desperately, make it through this period."

## Civilian Uses of Superintelligence

Initial development dominated by national security, but historical pattern for dual-use technologies:

**Nuclear parallel**:
- Chain reaction first harnessed as government project
- Nuclear weapons permanently reserved for government
- But civilian nuclear energy flourished privately (1960s-70s)

**Other examples**:
- Boeing: B-29/B-47/B-52 military → Boeing 707 commercial jets
- Radar, satellites, rockets, gene technology, WWII factories

**Expected path for superintelligence**:
- Initial period: national security exigency dominates
- Military uses remain government-reserved
- Safety norms enforced
- Once stabilized: companies in national consortium (and others) pursue civilian applications privately
- "Private, pluralistic, market-based, flourishing ecosystem of civilian applications will have its day"

## Free Variables: How It Could Go Better or Worse

### Timing (When, Not If)

Earlier realization better than mid-intelligence-explosion realization:
- Extra couple years for security crash program
- Time to get officials prepared
- Build functioning merged lab
- Avoid chaos of government stepping in only at very end
- Secrets/weights won't have already been stolen

### International Coalition

**Tighter alliance** (Quebec Agreement analog):
- Secret pact between US and close democratic allies
- Pool resources, coordinate on safety/security/military challenges
- Include: UK (DeepMind), Japan/South Korea (chip supply chain), NATO/core allies
- Mutual consent on use
- Helpful checks and balances on wielding superintelligence power

**Broader benefit-sharing** (Atoms for Peace/IAEA/NPT analog):
- Offer peaceful superintelligence benefits to wider group (including non-democracies)
- Commit to not offensive use against them
- In exchange: refrain from own superintelligence projects, safety commitments, dual-use restrictions
- Reduces incentives for arms races and proliferation
- Brings broad coalition under US-led umbrella for post-superintelligence world order

### Competence and Structure

"Perhaps the most important free variable is simply whether the inevitable government project will be competent."

**Critical questions**:
- How will it be organized?
- What does sane chain of command look like?
- How do checks and balances work?

"Scarcely any attention has gone into figuring this out. Almost all other AI lab and AI governance politicking is a sideshow. **This is the ballgame.**"

## The Endgame

**By 27/28**: Endgame underway
**By 28/29**: Intelligence explosion in progress
**By 2030**: Superintelligence summoned

### Person In Charge Will Face

- Build AGI fast
- Put American economy on wartime footing (hundreds of millions of GPUs)
- Lock it all down, weed out spies, fend off CCP attacks
- Manage hundred million AGIs automating AI research (decade's progress in year)
- Prevent rogue superintelligence attempting to seize control
- Use superintelligences to develop stabilization technologies
- Rapidly remake US forces for integration
- Navigate tensest international situation ever seen

"They better be good, I'll say that."

### For Those Who Get the Call

- "Stressful" but duty to serve free world and humanity
- Most important thing anyone involved will ever do
- Won't have ridiculously-overcomped-AI-researcher-lifestyle pleasantries
- But: same weirdly-small circle, scaling curves by day, hanging out on weekends
- Except: "the stakes will be all too real"

"See you in the desert, friends."

## Historical Parallel: Manhattan Project

Many parallels to early nuclear era:

**Initial skepticism** (1939-1940):
- Small group (Szilard, Einstein) saw atomic bomb possibility
- Most scientists dismissed as remote/speculative
- Conservative view was to play down possibility
- Gradually more scientists came to believe
- Once consensus formed: government saw national security exigency
- Manhattan Project launched

**Delayed response**:
- Einstein's 1939 letter → Advisory Committee formed
- Incompetent officials, little happened initially
- Fermi got only $6k (year's delay due to "short-sightedness and sluggishness")
- March 1941: British conclude bomb inevitable
- US initially ignored British report for months
- December 1941: Full-scale effort finally launched

**Secrecy**:
- Congress—even VP—didn't know about Manhattan Project
- "We probably shouldn't repeat that here"
- Key officials for The Project should require Senate confirmation

## See Also

- [[agi-timeline]]
- [[intelligence-explosion]]
- [[ai-security]]
- [[superalignment]]
- [[military-advantage-from-superintelligence]]
