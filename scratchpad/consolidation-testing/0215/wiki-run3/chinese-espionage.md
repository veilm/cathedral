# Chinese Espionage

Chinese espionage represents an existential threat to US AGI efforts, with current AI lab security providing essentially zero defense against state-actor infiltration.

## Scale of the Threat

FBI Director stated PRC has hacking operation greater than "every major nation combined." China engages in widespread industrial espionage already, and AI is becoming #1 priority.

**Recent example**: April 2024, Attorney General announced arrest of Chinese national who stole key AI code from Google to take back to PRC (theft occurred 2022/23). He evaded detection by copying code to Apple Notes, converting to PDF, uploading to personal account. Only caught because he did stupid things later (started prominent China startups, came back to US).

This illustrates how easy theft is even at Google, which likely has best AI lab security.

## When China "Wakes Up"

Currently, China hasn't fully mobilized for AGI race. But as we race through OOMs, as leaps continue, as $10T valuations appear and trillion-dollar clusters get built, CCP will wake up to:
- What AGI means for national power
- What being behind on AGI would mean
- That this is most important national security challenge

At that point, AI will become #1 priority of every Chinese intelligence agency. They'll employ extraordinary means and pay any cost to infiltrate AI labs.

## Capabilities

State actors have demonstrated ability to:
- Zero-click hack any iPhone/Mac with just phone number
- Infiltrate airgapped atomic weapons programs (Stuxnet)
- Modify Google source code (Operation Aurora)
- Find dozens of zero-days per year (averaging 7 years to detect)
- Spearfish major tech companies
- Install keyloggers on employee devices
- Insert trapdoors in encryption schemes
- Steal information via electromagnetic emanations or vibrations
- Use computer noise to determine map location or steal passwords
- Gain direct access to nuclear power plants
- Exfiltrate 22M security clearance files from USG
- Compromise supply chains at large scale
- Slip malicious code into software updates used by tech companies and USG

And that's just publicly known capabilities. Special operations, human intelligence (seduction, bribery, coercion), and other methods are less public but highly effective.

## Current AI Lab Vulnerability

**Security level**: "Random startup security" or "level 0" on frameworks requiring "level 3-4" for state-actor protection.

**Specific vulnerabilities**:
- Thousands with access to key secrets, minimal vetting
- No siloing, controls, or basic infosec
- Secrets stored on easily hackable SaaS services
- People discussing secrets at SF parties
- Anyone could be recruited to Chinese lab for $100M
- Can literally look through office windows
- Zero internal controls (random employees could go rogue unnoticed)

**Marc Andreessen's assessment**: "My own assumption is that all such American AI labs are fully penetrated and that China is getting nightly downloads of all American AI research and code RIGHT NOW."

## What's At Stake

**Algorithmic secrets** (immediate timeline): Key breakthroughs being developed in next 12-24 months. Worth 10x-100x compute advantage. Without them, China stuck at [[data-wall]]. With them, China matches US capabilities. See [[algorithmic-secrets-security]].

**Model weights** (2-3 year timeline): Steal AGI weights, get instant copy of superintelligence. Launch own [[intelligence-explosion]]. Any US lead vanishes. See [[model-weights-security]].

## The Failure Mode

Most likely way China stays competitive: Stealing US algorithmic secrets and/or model weights. On current course, we're basically delivering AGI to CCP directly.

Even worse scenario: China steals [[automated-ai-research]] weights on cusp of intelligence explosion, immediately launches their own, forcing existential race through superintelligence with zero safety margin.

## Why Private Labs Can't Fix This

Defending against MSS #1 priority effort requires government involvement:
- Vetting authority and ability to imprison for leaks
- Physical security infrastructure (military-base-level fortifications)
- NSA expertise on state-actor attacks
- Resources for airgapped facilities, constant monitoring, extreme access control
- Ability to impose invasive restrictions on researchers (working from SCIFs, reduced freedom to leave, etc.)

Microsoft regularly hacked by state actors (Russian hackers stole executive emails, government emails Microsoft hosts). Even with complete private crash course, high-level security experts estimate China would likely still exfiltrate AGI weights if it's their #1 priority. Only way to get to single-digit probability: Government project.

## Historical Parallel

In 1939-1941, Szilard fought for nuclear secrecy against fierce resistance. Scientists unused to it, ran counter to open science instincts. But military potential was too great to share with Nazis. Fermi's refusal to publish graphite results led Germans down wrong path (heavy water instead), dooming their bomb effort.

For AGI: Same pattern. Security seems excessive until clearly necessary. But by then might be too late.

See also: [[model-weights-security]], [[algorithmic-secrets-security]], [[lock-down-the-labs]]
